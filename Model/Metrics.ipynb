{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import sacrebleu\n",
    "\n",
    "# Device configuration\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bleu_metric(model, tokenizer):\n",
    "    # Example prompts for model generation\n",
    "    prompts = [\n",
    "        \"Once upon a time in a galaxy far, far away,\",\n",
    "        \"The protagonist was determined to find the hidden treasure,\"\n",
    "    ]\n",
    "\n",
    "    # Reference texts (expected ground truth)\n",
    "    references = [\n",
    "        \"Once upon a time in a galaxy far, far away, a great battle ensued between the forces of good and evil.\",\n",
    "        \"The protagonist was determined to find the hidden treasure, no matter the obstacles ahead.\"\n",
    "    ]\n",
    "\n",
    "    # Generate responses using the fine-tuned model\n",
    "    def generate_text(prompt, max_length=50):\n",
    "        inputs = tokenizer(\n",
    "                prompt, return_tensors=\"pt\", padding=True\n",
    "            ).to(device)\n",
    "        \n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        attention_mask = inputs[\"attention_mask\"]    \n",
    "\n",
    "        outputs = model.generate(\n",
    "                input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                eos_token_id=tokenizer.eos_token_id , \n",
    "                num_return_sequences=1 \n",
    "            )    \n",
    "        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    generated_texts = [generate_text(prompt) for prompt in prompts]\n",
    "\n",
    "    # Calculate BLEU score\n",
    "    bleu = sacrebleu.corpus_bleu(generated_texts, [references])\n",
    "\n",
    "    # Output results\n",
    "    print(\"Generated Texts:\")\n",
    "    for i, gen_text in enumerate(generated_texts):\n",
    "        print(f\"Prompt {i + 1}: {prompts[i]}\")\n",
    "        print(f\"Generated: {gen_text}\")\n",
    "        print(f\"Reference: {references[i]}\\n\")\n",
    "\n",
    "    print(f\"BLEU score: {bleu.score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Texts:\n",
      "Prompt 1: Once upon a time in a galaxy far, far away,\n",
      "Generated: Once upon a time in a galaxy far, far away, the best way to describe the current situation\n",
      "Reference: Once upon a time in a galaxy far, far away, a great battle ensued between the forces of good and evil.\n",
      "\n",
      "Prompt 2: The protagonist was determined to find the hidden treasure,\n",
      "Generated: The protagonist was determined to find the hidden treasure,_man found the treasure and found the treasure he\n",
      "Reference: The protagonist was determined to find the hidden treasure, no matter the obstacles ahead.\n",
      "\n",
      "BLEU score: 52.20981806658139\n"
     ]
    }
   ],
   "source": [
    "# Load fine tuned model.\n",
    "tokenizer_ft = AutoTokenizer.from_pretrained(\"../api/movie_10_100\")\n",
    "model_ft = AutoModelForCausalLM.from_pretrained(\"../api/movie_10_100\").to(device)\n",
    "tokenizer_ft.pad_token = tokenizer_ft.eos_token\n",
    "bleu_metric(model=model_ft, tokenizer=tokenizer_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Texts:\n",
      "Prompt 1: Once upon a time in a galaxy far, far away,\n",
      "Generated: Once upon a time in a galaxy far, far away, there was a man named Luke Skywalker.\n",
      "Reference: Once upon a time in a galaxy far, far away, a great battle ensued between the forces of good and evil.\n",
      "\n",
      "Prompt 2: The protagonist was determined to find the hidden treasure,\n",
      "Generated: The protagonist was determined to find the hidden treasure, but he was unable to find it.\n",
      "\n",
      "\n",
      "Reference: The protagonist was determined to find the hidden treasure, no matter the obstacles ahead.\n",
      "\n",
      "BLEU score: 52.91201132535046\n"
     ]
    }
   ],
   "source": [
    "tokenizer_og = AutoTokenizer.from_pretrained(\"gpt2-medium\")\n",
    "model_og = AutoModelForCausalLM.from_pretrained(\"gpt2-medium\").to(device)\n",
    "tokenizer_og.pad_token = tokenizer_og.eos_token\n",
    "bleu_metric(model=model_og, tokenizer=tokenizer_og)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
